# -*- coding: utf-8 -*-
"""titanic.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NfBcNbYVVygAqV_Xznoq4lwCRUBhl6fg
"""

# Gerekli kütüphaneleri import ederek başlıyoruz: Pandas veri işleme için,
# Numpy sayısal işlemler için, Seaborn ve Matplotlib ise görselleştirme için.
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt # plt olarak import etmek yaygın bir kullanımdır

# Veri setimizi Pandas DataFrame'i olarak yüklüyoruz.
# Colab'de çalıştığım için dosya yolunu bu şekilde verdim.
df = pd.read_csv("/content/train.csv")

# Verinin ilk 5 satırına göz atarak sütunları ve genel yapıyı anlamaya çalışıyorum.
df[0:5]

# İlk yorumum: Daha ilk 5 satırda bile "Cabin" sütununda 3 tane eksik (NaN) değer görüyorum.
# Bu sütunda ciddi bir eksik veri problemi olabilir.

# .info() metoduyla DataFrame'in genel bir özetini alıyorum.
# Sütun isimleri, her sütundaki dolu (non-null) veri sayısı ve veri tipleri burada görünüyor.
df.info()

# Yorumum: Evet, 'Cabin' sütununda sadece 204 dolu veri var (toplam 891 yolcudan).
# 'Age' sütununda da eksikler var (714 dolu veri). 'Embarked' sütununda ise sadece 2 eksik görünüyor.

# Emin olmak için .isnull().sum() ile her sütundaki eksik veri sayısını net olarak hesaplıyorum.
df.isnull().sum()

# Yorumum: 'Cabin'deki 687 eksik veri, bu sütunu analiz için neredeyse kullanışsız hale getiriyor.
# Muhtemelen bu sütunu daha sonra sileceğim. 'Age' (177 eksik) ve 'Embarked' (2 eksik) için bir çözüm bulmam gerekecek.

# .describe() ile sayısal sütunların istatistiksel özetine bakıyorum.
# Ortalama, standart sapma, min/max değerler ve çeyrek dilimler burada.
df.describe()

# Yorumum: Ortalama yaş ~29.7, en genç yolcu ~0.42 (5 aylık bebek), en yaşlı 80.
# 'Survived' ortalaması ~0.38, yani yolcuların yaklaşık %38'i hayatta kalmış.

# Veriyi daha iyi anlamak için görselleştirmeye başlıyorum. İlk olarak yaş dağılımına bakıyorum.
sns.histplot(df,x="Age")

# Yorumum: Yaş dağılımı histogramı, yolcuların çoğunluğunun genç yetişkinler (20-35 yaş) olduğunu gösteriyor.

# Şimdi yaş dağılımını hayatta kalma durumuna göre ayıralım ('hue' parametresi ile).
sns.histplot(df,x="Age",hue="Survived")

# Yorumum: Turuncular hayatta kalanlar (1), maviler kalamayanlar (0).
# Grafikten küçük çocukların hayatta kalma oranının daha yüksek olduğu,
# genç yetişkinlerin ise daha düşük olduğu anlaşılıyor. İlginç bir şekilde 80 yaşındaki yolcu hayatta kalmış.

# Cinsiyete göre yolcu sayısını görelim.
sns.countplot(df,x="Sex")

# Yorumum: Erkek yolcu sayısı kadınlardan belirgin şekilde fazla.

# Cinsiyetin hayatta kalma üzerindeki etkisine bakalım.
sns.countplot(df,x="Sex",hue="Survived")

# Yorumum: Kadınların hayatta kalma oranı erkeklere göre çok daha yüksek.
# "Önce kadınlar ve çocuklar" kuralının işlediğini gösteriyor.

# Bilet sınıfının etkisine bakalım.
sns.countplot(df,x="Pclass",hue="Survived")

# Yorumum: 1. sınıftakilerin hayatta kalma oranı en yüksek, 3. sınıftakilerin ise en düşük.
# Ekonomik durumun hayatta kalmada önemli bir faktör olduğunu görüyoruz.

# --- Veri Temizleme ve Hazırlama Aşaması ---

# Yorumum: Görselleştirmelerle veriyi anladık. Şimdi sıra, modeli eğitmeden önce
# veri setini temizlemeye geldi. Amacımız, eksik verileri doldurmak, metinleri sayılara çevirmek
# ve model için gereksiz olan sütunları çıkarmak.

# Önce işe yaramayacak ve çok fazla eksik içeren sütunları siliyorum.
df = df.drop(columns=["PassengerId","Name","Cabin","Ticket"])

# DataFrame'in son halini kontrol ediyorum.
df

# Yorumum: Sütunlar başarıyla silindi. Şimdi eksik verileri doldurma zamanı.
# 'Age' ve 'Embarked' sütunlarında eksikler vardı.

# 'Age' sütunundaki eksikleri, tüm yolcuların ortalama yaşıyla doldurmak mantıklı bir başlangıç.
# Önce ortalamayı hesaplayalım.
df["Age"].mean()

# Yorumum: Ortalama yaş 29.69...

# Şimdi .fillna() metoduyla 'Age' sütunundaki NaN değerleri bu ortalama ile dolduruyorum.
# Fonksiyonu çağırmak için sonuna () eklemeyi unutmuyorum!
df["Age"] = df["Age"].fillna(df["Age"].mean())

# Doldurma işleminin başarılı olup olmadığını kontrol ediyorum (0 çıkmalı).
df["Age"].isnull().sum()

# Yorumum: Harika, 'Age' sütununda eksik veri kalmadı. Şimdi sıra 'Embarked' sütununda.
# Burada sadece 2 eksik vardı. Bunları, en sık görülen biniş limanıyla doldurmak mantıklı.
# Önce en sık görülen değeri (modu) bulalım.
df["Embarked"].mode()

# Yorumum: En sık biniş yapılan liman 'S' imiş. .mode() bir Series döndürdüğü için ilk elemanını ([0]) alacağız.

# Şimdi 'Embarked' sütunundaki NaN değerleri 'S' ile dolduruyorum.
df["Embarked"] = df["Embarked"].fillna(df["Embarked"].mode()[0])

# Kontrol edelim (0 çıkmalı).
df["Embarked"].isnull().sum()

# Yorumum: 'Embarked' sütunu da tamamlandı. Şimdi sıra metinleri sayılara çevirmekte.
# 'Sex' ve 'Embarked' sütunları 'object' tipinde.

# 'Embarked' sütununda 3 farklı kategori ('S', 'C', 'Q') var. Bunları 0, 1, 2 gibi kodlarsak,
# model aralarında bir sıralama olduğunu düşünebilir. Bu yüzden One-Hot Encoding (get_dummies) kullanıyoruz.
df = pd.get_dummies(df,"Embarked")

# DataFrame'in son halini kontrol edelim. 'Embarked' gitti, yerine 'Embarked_S', 'Embarked_C', 'Embarked_Q' geldi.
df

# Tüm sütunlarda eksik veri kalıp kalmadığını son kez kontrol ediyorum.
df.isnull().sum()

# Yorumum: Embarked dönüşümü tamam. Sadece 'Sex' sütunu kaldı.
# Burada sadece iki kategori ('male', 'female') olduğu için basit bir .map() yeterli olacaktır.
mapping = {"male":0,"female":1}
df["Sex"]= df["Sex"].map(mapping)

# DataFrame'in son halini kontrol ediyorum.
df

# Yorumum: Veri seti tam anlamıyla eğitime hazır! Hiç eksik veri yok ve tüm veriler sayısal.

# --- Model Eğitimi Aşaması ---

# Modeli eğitmeden önce, veriyi eğitim ve test setlerine ayırmamız gerekiyor.
# Bu, modelin ezber yapıp yapmadığını anlamamızı sağlar.
from sklearn.model_selection import train_test_split

# Yorumum: Önce hedef değişkenimizi (tahmin etmek istediğimiz şey) 'y' olarak ayıralım.
y = df["Survived"]

# Geri kalan tüm sütunlar ise özelliklerimiz (modelin öğrenmek için kullanacağı bilgiler) 'X' olacak.
X = df.drop(columns=["Survived"])

# 'y' değişkenini kontrol edelim.
y

# 'X' değişkenini kontrol edelim.
X

# Yorumum: X ve y hazır. Şimdi train_test_split fonksiyonu ile bunları bölelim.
# Verinin %20'sini test için ayıracağız (test_size=0.2).
# random_state=42 kullanarak bölme işleminin her seferinde aynı şekilde yapılmasını sağlıyoruz.
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Yorumum: Eğitim ve test setlerimiz hazır. Şimdi modelimizi seçip import edelim.
# Basit ama etkili bir başlangıç modeli olan Lojistik Regresyon'u kullanacağız.
from sklearn.linear_model import LogisticRegression

# Modeli oluştururken, 'ConvergenceWarning' almamak için max_iter parametresini yüksek bir değere ayarlıyorum.
model = LogisticRegression(max_iter=4000)
# Modeli eğitim verileriyle eğitiyorum ('fit' metodu ile).
model.fit(X_train,y_train)

# Yorumum: Modelimiz eğitildi! Şimdi performansını daha önce hiç görmediği test verileriyle ölçelim.
# Bunun için .score() metodunu kullanıyoruz.
model.score(X_test,y_test)

# Yorumum: %81 doğruluk! İlk model için harika bir başlangıç skoru.
# Bu, modelimizin eğitim verisinden anlamlı desenler öğrendiğini ve bunları yeni verilere genelleyebildiğini gösteriyor.

# --- Kaggle İçin Tahmin Üretme ---

# Yorumum: Modelimizin performansından memnunuz. Şimdi sıra Kaggle'ın verdiği 'test.csv' dosyasındaki
# yolcular için tahmin üretip sonucu Kaggle'a göndermekte.

# Önce 'test.csv' dosyasını yükleyelim.
test_df = pd.read_csv("/content/test.csv")

# İlk 5 satırına bakalım. 'Survived' sütunu yok, tahmin etmemiz gereken bu.
test_df[0:5]

# test_df'in genel bilgilerine bakalım. Eksik veriler var mı?
test_df.info()

# Eksik verileri tam olarak sayalım.
test_df.isnull().sum()

# Yorumum: Evet, 'Age', 'Fare' ve 'Cabin' sütunlarında eksikler var.
# 'train.csv'ye uyguladığımız BİREBİR AYNI temizleme adımlarını 'test_df'ye de uygulamalıyız.

# Eksik 'Age' değerlerini, EĞİTİM SETİNİN ortalamasıyla dolduruyoruz.
test_df["Age"] = test_df["Age"].fillna(df["Age"].mean()) # df['Age'].mean() kullandığıma dikkat!

# Eksik 'Age' kalmadığını kontrol edelim.
test_df["Age"].isnull().sum()

# Eksik 'Fare' değerini (sadece 1 tane vardı), EĞİTİM SETİNİN medyanıyla doldurmak iyi bir fikir.
test_df["Fare"] = test_df["Fare"].fillna(df["Fare"].median()) # df['Fare'].median() kullandığıma dikkat!

# Gereksiz sütunları 'test_df'den de silelim.
# NOT: PassengerId'yi SİLMEDEN ÖNCE bir kenara kaydetmemiz gerekecek!
passenger_ids_for_submission = test_df['PassengerId'] # Önce ID'leri kaydedelim
test_df = test_df.drop(columns=["PassengerId","Name","Ticket","Cabin"])

# 'test_df'nin son halini kontrol edelim.
test_df

# 'Sex' sütununu sayısala çevirelim.
mapping = {"male":0,"female":1}
test_df["Sex"] = test_df["Sex"].map(mapping)

# 'Sex' sütununu kontrol edelim.
test_df["Sex"]

# 'Embarked' sütununu One-Hot Encoding ile dönüştürelim.
test_df = pd.get_dummies(test_df,"Embarked")

# 'test_df'nin son halini kontrol edelim.
test_df

# Tüm eksik verilerin gittiğinden emin olalım.
test_df.isnull().sum()

# Yorumum: Harika! 'test_df' artık temizlendi ve formatı 'X_train' ile aynı.
# Şimdi eğitilmiş modelimizi kullanarak tahminleri yapabiliriz.
test_tahminleri = model.predict(test_df)

# Tahmin sonuçlarına (0'lar ve 1'ler) bakalım.
test_tahminleri

# Yorumum: Tahminler hazır. Şimdi bunları Kaggle'ın istediği formata (PassengerId, Survived) getirelim.
# Daha önce kaydettiğimiz passenger_ids_for_submission değişkenini kullanacağız.

# İki sütunu birleştiren bir dictionary oluşturalım.
data = {"PassengerId": passenger_ids_for_submission, "Survived": test_tahminleri}

# Bu dictionary'den bir Pandas DataFrame oluşturalım.
submission_df = pd.DataFrame(data)

# Oluşan DataFrame'e bakalım. Tam istediğimiz gibi görünüyor.
submission_df

# Son adım: Bu DataFrame'i 'submission.csv' adıyla kaydedelim.
# Kaggle index'i istemediği için index=False parametresini kullanıyoruz.
submission_df.to_csv('submission.csv', index=False)

# Yorumum: Dosya kaydedildi! Şimdi Colab'in solundaki Dosyalar menüsünden
# 'submission.csv' dosyasını indirip Kaggle'a yükleyebilirim.
# Kaggle skorum: 0.78555 (%78.6). Kendi test setimdeki %81'e oldukça yakın, modelimiz iyi çalışıyor!